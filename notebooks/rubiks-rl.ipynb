{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-24T14:49:59.815502Z","iopub.status.busy":"2023-12-24T14:49:59.815154Z","iopub.status.idle":"2023-12-24T14:49:59.837241Z","shell.execute_reply":"2023-12-24T14:49:59.836327Z","shell.execute_reply.started":"2023-12-24T14:49:59.815472Z"},"id":"KsmeM68VWXlT","outputId":"dc2b5e53-4dce-4e3b-ac40-8e3e6c6dac66","trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-24T14:50:00.197725Z","iopub.status.busy":"2023-12-24T14:50:00.197365Z","iopub.status.idle":"2023-12-24T14:50:51.210787Z","shell.execute_reply":"2023-12-24T14:50:51.209583Z","shell.execute_reply.started":"2023-12-24T14:50:00.197697Z"},"id":"KIfxXMb-0mDo","outputId":"d9446979-18b6-4522-a1fa-c42981c5947f","trusted":true},"outputs":[],"source":["# install from git\n","!if [ -e ./rubiks ]; then rm -rf ./rubiks; fi\n","!pip uninstall rubiks_rl -y --quiet\n","!git clone https://github.com/LongDangHoang/rubik_rl ./rubiks --quiet\n","!cd ./rubiks; pip install . --quiet; cd ..\n","\n","# some packages\n","!pip install torchinfo python-dotenv wandb==0.15.0 protobuf==3.20.3 matplotlib --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-24T14:50:51.213239Z","iopub.status.busy":"2023-12-24T14:50:51.212826Z","iopub.status.idle":"2023-12-24T14:50:53.581579Z","shell.execute_reply":"2023-12-24T14:50:53.580558Z","shell.execute_reply.started":"2023-12-24T14:50:51.213209Z"},"id":"uOV-ZL_E2ryi","trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import functools\n","import pythreejs as p3\n","\n","from torchinfo import summary\n","from pathlib import Path\n","from tqdm import tqdm\n","\n","from rubiks_rl.colors import Color\n","from rubiks_rl.rubik54 import Rubik54\n","from rubiks_rl.models import RLRubikModel \n","from rubiks_rl.s3_utils import S3Syncer\n","from rubiks_rl.world import *\n","from rubiks_rl.logs import RubiksLogger\n","\n","orig_seed = 314\n","torch.manual_seed(orig_seed)\n","torch.cuda.manual_seed_all(orig_seed)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-24T14:50:53.584003Z","iopub.status.busy":"2023-12-24T14:50:53.583401Z","iopub.status.idle":"2023-12-24T14:51:28.386678Z","shell.execute_reply":"2023-12-24T14:51:28.385732Z","shell.execute_reply.started":"2023-12-24T14:50:53.583966Z"},"id":"7sIKMKSf3r2p","trusted":true},"outputs":[],"source":["# set environment\n","from dotenv import load_dotenv\n","ON_KAGGLE = False\n","if not load_dotenv():\n","    from kaggle_secrets import UserSecretsClient\n","    os.environ[\"WANDB_API_KEY\"] = UserSecretsClient().get_secret(\"wandb_api\")\n","    os.environ[\"AWS_ACCESS_KEY_ID\"] = UserSecretsClient().get_secret(\"s3_aws_access_key\")\n","    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = UserSecretsClient().get_secret(\"s3_aws_secret_access_key\")\n","    ON_KAGGLE = True\n","    \n","import wandb\n","\n","# Define hyper parameters\n","max_depth_scramble = 30\n","num_cubes = 1_024\n","num_epochs = 5000\n","num_blocks = 128\n","batch_size = 8192\n","accumulate_grad_batches = None\n","use_constant_lr = False\n","weight_decay = 0.01\n","refresh_every_n_epoch = 1\n","lr = 2e-4\n","use_rl_model = True\n","\n","# run ids\n","log_wandb = True\n","use_existing_run = None\n","use_pretrain = None\n","init_new_wandb_run = True\n","\n","# start a new wandb run to track this script\n","if log_wandb:\n","    wandb.login()\n","\n","    if \"run\" not in globals():\n","        run = wandb.init(\n","            project=\"rubiks_rl\",\n","            id=use_existing_run if (use_existing_run and not init_new_wandb_run) else None,\n","            resume=\"must\" if (use_existing_run and not init_new_wandb_run) else None,\n","            config=dict(\n","                max_depth_scramble=max_depth_scramble,\n","                num_cubes=num_cubes,\n","                num_epochs=num_epochs,\n","                num_blocks=num_blocks,\n","                batch_size=batch_size,\n","                accumulate_grad_batches=accumulate_grad_batches,\n","                use_constant_lr=use_constant_lr,\n","                refresh_every_n_epoch=refresh_every_n_epoch,\n","                weight_decay=weight_decay,\n","                lr=lr,\n","                use_rl_model=use_rl_model\n","            )\n","        )\n","        assert run is not None"]},{"cell_type":"markdown","metadata":{},"source":["Load model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-24T14:51:28.389090Z","iopub.status.busy":"2023-12-24T14:51:28.388674Z","iopub.status.idle":"2023-12-24T14:51:30.349681Z","shell.execute_reply":"2023-12-24T14:51:30.348784Z","shell.execute_reply.started":"2023-12-24T14:51:28.389062Z"},"id":"Ul8Qw2mDsKTQ","outputId":"b5627c47-52a3-4eb4-e4d4-301ca85f7874","trusted":true},"outputs":[],"source":["# setting up checkpoint \n","save_ckpt_local_dir = (\n","    Path(f\"./rubiks_rl/{run.id}/checkpoints\") \n","    if 'run' in globals() \n","    else Path(f\"./rubiks_rl/local_run/checkpoints\")\n",")\n","save_ckpt_local_dir.mkdir(parents=True, exist_ok=True)\n","\n","if use_existing_run:\n","    load_ckpt_local_dir = Path(f\"./rubiks_rl/{use_existing_run}/checkpoints\")\n","    load_ckpt_local_dir.mkdir(parents=True, exist_ok=True)\n","else:\n","    load_ckpt_local_dir = None\n","\n","s3_syncer = S3Syncer(\n","    save_local_dir=save_ckpt_local_dir, \n","    load_local_dir=load_ckpt_local_dir, \n","    every_n_epochs=1\n",")\n","\n","if use_existing_run:\n","    s3_syncer.download_files_from_s3()\n","    \n","if use_pretrain and not use_existing_run: # if resuming run, no need to pretrain\n","    pretrain_ckpt_path = (Path(\".\") / use_pretrain)\n","    pretrain_ckpt_local_dir = pretrain_ckpt_path.parent\n","    pretrain_ckpt_local_dir.mkdir(parents=True, exist_ok=True)\n","        \n","    s3_pretrain_sync = S3Syncer(save_local_dir=pretrain_ckpt_local_dir, load_local_dir=pretrain_ckpt_local_dir)\n","    if not pretrain_ckpt_path.exists():\n","        s3_pretrain_sync.download_filename(pretrain_ckpt_path.name) \n","        assert pretrain_ckpt_path.exists()\n","    \n","    state_dict = torch.load(pretrain_ckpt_path)\n","    model = RLRubikModel()\n","    model.load_state_dict(state_dict[\"model_state_dict\"])\n","elif use_existing_run:\n","    state_dict = torch.load(s3_syncer.load_local_dir / \"last.ckpt\")\n","    model = RLRubikModel()\n","    model.load_state_dict(state_dict[\"model_state_dict\"])\n","else:\n","    model = RLRubikModel()\n","    \n","model = model.to(device)\n","summary(model, input_shape=(16, 54, 6))"]},{"cell_type":"markdown","metadata":{"id":"Z7iy4a9JXie4"},"source":["## Policy iteration loop\n","\n","- How far in the scramble do we want?\n","    - If we have the model learn on few steps, it may struggle as the number of steps increase? Best to have this as a parameter\n","- For each sample, find best action by evaluating on breadth-1\n","    - First, generate in a batch fashion the states to be evaluated\n","    - This will have shape (num_cubes * max_depth_scramble * 12, 54, 6)\n","- Then, evaluate the batch and add in the reward (-1 if state not solve, else 1)\n","- Retrieve the bootstrapped labels by taking the argmax over the reward\n","- Train the model using this output labels (num_cubes * max_depth_scramble) (by chunking over shape of 12)\n","    - We also apply weighting based on scramble distance to the average when taking the loss\n","- This forms one epoch. Should profile\n","- repeat until reach `num_epochs`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-24T14:51:30.351452Z","iopub.status.busy":"2023-12-24T14:51:30.351021Z","iopub.status.idle":"2023-12-24T14:51:30.405607Z","shell.execute_reply":"2023-12-24T14:51:30.404556Z","shell.execute_reply.started":"2023-12-24T14:51:30.351418Z"},"trusted":true},"outputs":[],"source":["# set up optimiser and learning rate scheduler\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","lr_sched = optim.lr_scheduler.OneCycleLR(\n","    optimizer, \n","    max_lr=lr*10, \n","    epochs=num_epochs, \n","    steps_per_epoch=int(np.ceil(num_cubes*max_depth_scramble/batch_size))\n",")\n","\n","# apply states\n","if use_existing_run and (\"state_dict\" in globals()):\n","    optimizer.load_state_dict(state_dict[\"optimizer_state_dict\"])\n","    lr_sched.load_state_dict(state_dict[\"scheduler_state_dict\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-24T14:54:37.808945Z","iopub.status.busy":"2023-12-24T14:54:37.808103Z","iopub.status.idle":"2023-12-24T15:02:41.069850Z","shell.execute_reply":"2023-12-24T15:02:41.068298Z","shell.execute_reply.started":"2023-12-24T14:54:37.808917Z"},"id":"cqhmhDRH5gpT","trusted":true},"outputs":[],"source":["# run training\n","pbar = tqdm(total=num_epochs, dynamic_ncols=True)\n","save_path = None\n","metrics_logger = RubiksLogger(prefix=\"train\")\n","\n","if log_wandb:\n","    wandb.watch(model)\n","\n","# skip epochs if use_pretrain\n","start_training_epoch = 0\n","if use_existing_run and (\"state_dict\" in globals()):\n","    start_training_epoch = (lr_sched._step_count - 1) / int(np.ceil(num_cubes*max_depth_scramble/batch_size))\n","\n","for epoch_n in range(num_epochs):\n","    if epoch_n < start_training_epoch:\n","        pbar.update(1)\n","        continue\n","        \n","    # get new data\n","    if epoch_n % refresh_every_n_epoch == 0 or (\"best_cube_state_values\" not in globals()):\n","        seed = epoch_n - (epoch_n % refresh_every_n_epoch)\n","        X = get_n_cubes_k_scrambles(num_cubes=num_cubes, max_depth_scramble=max_depth_scramble, seed=seed)[\"data\"]\n","        weight = get_weights_by_scrambling_distance(num_cubes=num_cubes, max_depth_scramble=max_depth_scramble)\n","        # generate bootstrapped labels using bfs\n","        evaluate_fn = functools.partial(model_evaluate, model=model, batch_size=batch_size*32, device=device)\n","        best_action, best_cube_state_values = find_best_move_and_value_from(X, evaluate_fn)\n","        \n","        # sanity check\n","        # for speed randomly sample 100 cubes in num_cubes\n","        for i in random.sample(range(num_cubes), k=100):\n","            turn = CUBE.turn_mat[best_action[i]]\n","            assert np.all(X[i][turn] == CUBE.get_solved_state()), f\"Model stops being able to solve scramble distance 1 at epoch {epoch_n}\"\n","        \n","        if log_wandb:\n","            solved_cube_state_value = best_cube_state_values[(X == CUBE.get_solved_state()).all(axis=1).all(axis=1)][0]\n","            avg_target_state_values = [solved_cube_state_value] + list(best_cube_state_values[:num_cubes*10].reshape((10, num_cubes)).mean(axis=1))\n","            for d in range(11):\n","                wandb.log({f\"target_state_value_d={d}\": avg_target_state_values[d]})\n","        \n","        print(f\"Finish generating training data using model at epoch {epoch_n}\")\n","\n","        # shuffle ids, but remove ids for solved state as we won't see the state at inference time\n","        ids = np.arange(len(X))[~(X == np.expand_dims(CUBE.get_solved_state(), 0)).all(axis=(1, 2))]\n","        generator = np.random.default_rng(seed=seed)\n","        ids = generator.permutation(ids)\n","\n","    # train the model\n","    model.train()\n","    metrics_logger.refresh()\n","    for batch_start_idx in range(0, len(X), batch_size):\n","        batch_ids = ids[batch_start_idx:batch_start_idx+batch_size]\n","        optimizer.zero_grad()\n","        batch = torch.as_tensor(X[batch_ids], device=device, dtype=torch.float32)\n","        v, p = model(batch)\n","        p_lab = torch.as_tensor(best_action[batch_ids], device=device, dtype=torch.int64)\n","        v_lab = torch.as_tensor(best_cube_state_values[batch_ids], device=device, dtype=torch.float32).unsqueeze(1)\n","        loss_weight = torch.as_tensor(weight[batch_ids], device=device, dtype=torch.float32)\n","        \n","        loss_v = F.mse_loss(v, v_lab, reduction=\"none\").reshape((-1,))\n","        loss_p = F.cross_entropy(p, p_lab, reduction=\"none\").reshape((-1,))\n","        total_loss = loss_v + loss_p\n","        \n","        weighted_loss = (total_loss * loss_weight).mean()\n","        weighted_loss.backward()\n","        optimizer.step()\n","        lr_sched.step()\n","        \n","        if log_wandb:\n","            wandb.log({'lr': lr_sched.get_last_lr()[0]})\n","        \n","        # add to metric logger\n","        metrics_logger.update({\n","            \"total_loss\": total_loss.detach().cpu().numpy(),\n","            \"policy_loss\": loss_p.detach().cpu().numpy(),\n","            \"state_value_loss\": loss_v.detach().cpu().numpy(),\n","            \"weight\": loss_weight.detach().cpu().numpy(),\n","        })\n","        \n","    \n","    if log_wandb:\n","        wandb.log({\n","            \"train_epoch_avg_weighted_loss\": metrics_logger.avg_weighted_loss,\n","            \"train_epoch_avg_weighted_state_value_loss\": metrics_logger.avg_weighted_state_value_loss,\n","            \"train_epoch_avg_weighted_policy_loss\": metrics_logger.avg_weighted_policy_loss,\n","        })\n","\n","    # save to checkpoint\n","    checkpoint = {\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'scheduler_state_dict': lr_sched.state_dict(),\n","    }\n","    torch.save(checkpoint, s3_syncer.save_local_dir / 'last.ckpt')\n","    if epoch_n > 0 and epoch_n % 10 == 0:\n","        for file in s3_syncer.save_local_dir.iterdir():\n","            if file.name != \"last.ckpt\":\n","                os.remove(file)\n","        torch.save(checkpoint, s3_syncer.save_local_dir / f'epoch={epoch_n}.ckpt')\n","        \n","        if log_wandb:\n","            s3_syncer.upload_files_to_s3()\n","            print(f\"Pushed model at epoch={epoch_n} to s3\")\n","        \n","    # update pbar\n","    pbar.update(1)\n","    if log_wandb:\n","        wandb.log({'epoch': epoch_n})"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30558,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
