{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsmeM68VWXlT",
        "outputId": "dc2b5e53-4dce-4e3b-ac40-8e3e6c6dac66"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install from git\n",
        "!if [ -e ./rubiks ]; then rm -rf ./rubiks; fi\n",
        "!pip uninstall rubiks_rl -y --quiet\n",
        "!git clone https://github.com/LongDangHoang/rubik_rl ./rubiks --quiet\n",
        "!cd ./rubiks; pip install . --quiet; cd ..\n",
        "\n",
        "# some packages\n",
        "!pip install torchinfo wandb --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIfxXMb-0mDo",
        "outputId": "d9446979-18b6-4522-a1fa-c42981c5947f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rubiks-rl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pythreejs as p3\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "from rubiks_rl.colors import Color\n",
        "from rubiks_rl.rubik54 import Rubik54\n",
        "from rubiks_rl.models import RubikModel\n",
        "from rubiks_rl.world import *\n",
        "\n",
        "from google.colab import output\n",
        "from IPython.display import display\n",
        "\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "uOV-ZL_E2ryi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyper parameters\n",
        "max_depth_scramble = 20\n",
        "num_cubes = 100\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "7sIKMKSf3r2p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how far in the scramble do we want?\n",
        "#### If we have the model learn on few steps, it may struggle as the number of steps increase?\n",
        "#### best to have this as a parameter\n",
        "# for each sample, find best action by evaluating on breadth-1\n",
        "#### first, generate in a batch fashion the states to be evaluated\n",
        "#### this will have shape (num_cubes * max_depth_scramble * 12, 54, 6)\n",
        "#### evaluate the batch and add in the reward (-1 if state not solve, else 1)\n",
        "#### then, retrieve the bootstrapped labels by taking the argmax over the reward\n",
        "# train the model using this output labels (num_cubes * max_depth_scramble) (by chunking over shape of 12)\n",
        "## we also apply weighting based on scramble distance to the average when taking the loss\n",
        "## this forms one epoch. Should profile\n",
        "## repeat until reach max_epoch"
      ],
      "metadata": {
        "id": "4c9RX1CjwIHs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RubikModel(num_blocks=3).to(device)\n",
        "\n",
        "# count params\n",
        "summary(model, input_size=(16, 54, 6))"
      ],
      "metadata": {
        "id": "Ul8Qw2mDsKTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5627c47-52a3-4eb4-e4d4-301ca85f7874"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "RubikModel                               [16, 1]                   --\n",
              "├─Flatten: 1-1                           [16, 324]                 --\n",
              "├─Sequential: 1-2                        [16, 324]                 --\n",
              "│    └─Block: 2-1                        [16, 324]                 --\n",
              "│    │    └─BatchNorm1d: 3-1             [16, 324]                 648\n",
              "│    │    └─Linear: 3-2                  [16, 324]                 105,300\n",
              "│    │    └─ELU: 3-3                     [16, 324]                 --\n",
              "│    │    └─BatchNorm1d: 3-4             [16, 324]                 (recursive)\n",
              "│    │    └─MultiheadAttention: 3-5      [16, 324]                 421,200\n",
              "│    │    └─ELU: 3-6                     [16, 324]                 --\n",
              "│    └─Block: 2-2                        [16, 324]                 --\n",
              "│    │    └─BatchNorm1d: 3-7             [16, 324]                 648\n",
              "│    │    └─Linear: 3-8                  [16, 324]                 105,300\n",
              "│    │    └─ELU: 3-9                     [16, 324]                 --\n",
              "│    │    └─BatchNorm1d: 3-10            [16, 324]                 (recursive)\n",
              "│    │    └─MultiheadAttention: 3-11     [16, 324]                 421,200\n",
              "│    │    └─ELU: 3-12                    [16, 324]                 --\n",
              "│    └─Block: 2-3                        [16, 324]                 --\n",
              "│    │    └─BatchNorm1d: 3-13            [16, 324]                 648\n",
              "│    │    └─Linear: 3-14                 [16, 324]                 105,300\n",
              "│    │    └─ELU: 3-15                    [16, 324]                 --\n",
              "│    │    └─BatchNorm1d: 3-16            [16, 324]                 (recursive)\n",
              "│    │    └─MultiheadAttention: 3-17     [16, 324]                 421,200\n",
              "│    │    └─ELU: 3-18                    [16, 324]                 --\n",
              "├─Linear: 1-3                            [16, 1]                   325\n",
              "├─Linear: 1-4                            [16, 12]                  3,900\n",
              "==========================================================================================\n",
              "Total params: 1,585,669\n",
              "Trainable params: 1,585,669\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 5.18\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 0.37\n",
              "Params size (MB): 1.29\n",
              "Estimated Total Size (MB): 1.68\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Policy iteration loop"
      ],
      "metadata": {
        "id": "Z7iy4a9JXie4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "id": "cqhmhDRH5gpT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}